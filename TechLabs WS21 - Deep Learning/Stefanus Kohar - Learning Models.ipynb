{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TechLabs WS21, Learning Models\n",
    "#### Stefanus Kohar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work notes :\n",
    "- Tensorflow regression tutorial : https://www.tensorflow.org/tutorials/keras/regression\n",
    "- sample from Notion page : https://towardsdatascience.com/regression-based-neural-networks-with-tensorflow-v2-0-predicting-average-daily-rates-e20fffa7ac9a\n",
    "- MinMax scaler used, after preliminary testing on RF, slightly better result with MinMax\n",
    "\n",
    "Resources :\n",
    "- Standardization - Normalization : https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/\n",
    "- Gaussian processes, using tensorflow : https://peterroelants.github.io/posts/gaussian-process-tutorial/\n",
    "    - Understanding usage of Kernel, for SciKit Gaussian\n",
    "    - Kernel documentation (scikit) : https://scikit-learn.org/stable/modules/gaussian_process.html#kernels-for-gaussian-processes\n",
    "- Evaluation Metrics : https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce (member only, limited free read available)\n",
    "\n",
    "to explore :\n",
    "- Gaussian process model (https://scikit-learn.org/stable/modules/gaussian_process.html)\n",
    "    - sample from kaggle : https://www.kaggle.com/carlmcbrideellis/gaussian-process-regression-sample-script\n",
    "- Pytorch tabular : https://pytorch-tabular.readthedocs.io/en/latest/, to read though each section\n",
    "    - withdrawn, compatibility issues.\n",
    "\n",
    "problems :\n",
    "- 02/03, xlrd reader engine problem (__solve__, reinstall pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional Module, to be added singularly for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import math\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "from xgboost import plot_tree\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_tabular packages, abandoned\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Future development, automatically pulling sheet names\n",
    "sheet = pd.ExcelFile(\"sample.xlsx\")\n",
    "sheet_count = len(sheet.sheet_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Please extract file before continuing further___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"A-to-B.xlsx\"\n",
    "AB_TC = pd.read_excel(file, sheet_name=\"Sheet C\")\n",
    "AB_TB = pd.read_excel(file, sheet_name=\"Sheet B\")\n",
    "AB_TA = pd.read_excel(file, sheet_name=\"Sheet A\")\n",
    "AB_all = pd.read_excel(\"A-to-B_combined.xlsx\")\n",
    "\n",
    "file = \"B-to-D.xlsx\"\n",
    "BD_TC = pd.read_excel(file, sheet_name=\"Sheet C\")\n",
    "BD_TB = pd.read_excel(file, sheet_name=\"Sheet B\")\n",
    "BD_TA = pd.read_excel(file, sheet_name=\"Sheet A\")\n",
    "BD_all = pd.read_excel(\"B-to-D_combined.xlsx\")\n",
    "\n",
    "file = \"A-to-D.xlsx\"\n",
    "AD_TC = pd.read_excel(file, sheet_name=\"Sheet C\")\n",
    "AD_TB = pd.read_excel(file, sheet_name=\"Sheet B\")\n",
    "AD_TA = pd.read_excel(file, sheet_name=\"Sheet A\")\n",
    "AD_all = pd.read_excel(\"A-to-D_combined.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Data Preparation___<br>\n",
    "(Same scaling and transformation for all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = AD_all.iloc[:,[2,6,7,8,9,10]].copy()\n",
    "cols = data.columns\n",
    "results = pd.DataFrame(columns=['MAE', 'RMSE', 'SI', 'Pearson'])\n",
    "\n",
    "X = data.iloc[:,[1,2,3,4,5]]\n",
    "Y = data.iloc[:,0].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 3, shuffle = True)\n",
    "\n",
    "Y_train = np.reshape(Y_train, (-1,1))\n",
    "Y_test = np.reshape(Y_test, (-1,1))\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "Y_scaler = MinMaxScaler().fit(Y_train)\n",
    "\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "Y_train = Y_scaler.transform(Y_train)\n",
    "Y_test_sc = Y_scaler.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(criterion='absolute_error', max_depth=40,\n",
       "                      min_samples_split=5, n_estimators=120)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(max_depth=40,n_estimators=120, criterion='absolute_error', min_samples_split=5)\n",
    "rf.fit(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_rf = rf.predict(X_test)\n",
    "Y_rf = np.reshape(Y_rf, (-1,1))\n",
    "Y_rf = Y_scaler.inverse_transform(Y_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = metrics.mean_absolute_error(Y_test, Y_rf)\n",
    "rmse = metrics.mean_squared_error(Y_test, Y_rf, squared = False)\n",
    "\n",
    "SI = (rmse/Y_rf.mean())*100\n",
    "\n",
    "pear = stats.pearsonr(Y_test.ravel(), Y_rf)\n",
    "\n",
    "met_rf = pd.DataFrame([[mae, rmse, SI, pear[0].item()]], columns=results.columns, index=['Random Forest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               768       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 927\n",
      "Trainable params: 927\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Dense(5, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
    "nn.add(Dense(128,activation='relu'))\n",
    "nn.add(Dense(1))\n",
    "nn.summary()\n",
    "\n",
    "nn.compile(loss='mae', optimizer='adam', metrics=['mse','mae'])\n",
    "nn_report=nn.fit(X_train, Y_train, epochs=50, verbose=0, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_nn = nn.predict(X_test)\n",
    "Y_nn = np.reshape(Y_nn, (-1,1))\n",
    "Y_nn = Y_scaler.inverse_transform(Y_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss Report\n",
    "plt.plot(nn_report.history['loss'])\n",
    "plt.plot(nn_report.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = metrics.mean_absolute_error(Y_test, Y_nn)\n",
    "rmse = metrics.mean_squared_error(Y_test, Y_nn, squared = False)\n",
    "\n",
    "SI = (rmse/Y_nn.mean())*100\n",
    "\n",
    "pear = stats.pearsonr(Y_test.ravel(), Y_nn)\n",
    "\n",
    "met_nn = pd.DataFrame([[mae, rmse, SI, pear[0].item()]], columns=results.columns, index=['Neural Network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset session, for model changes\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr_kernel = DotProduct() + WhiteKernel(noise_level=0.5)\n",
    "gpr = GaussianProcessRegressor(kernel=gpr_kernel).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_gpr = gpr.predict(X_test)\n",
    "Y_gpr = np.reshape(Y_gpr, (-1,1))\n",
    "Y_gpr = Y_scaler.inverse_transform(Y_gpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = metrics.mean_absolute_error(Y_test, Y_gpr)\n",
    "rmse = metrics.mean_squared_error(Y_test, Y_gpr, squared = False)\n",
    "\n",
    "SI = (rmse/Y_gpr.mean())*100\n",
    "\n",
    "pear = stats.pearsonr(Y_test.ravel(), Y_gpr)\n",
    "\n",
    "met_gpr = pd.DataFrame([[mae, rmse, SI, pear[0].item()]], columns=results.columns, index=['Gaussian Process'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch Tabular, abandoned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(target=X.columns, continuous_cols=X.columns)\n",
    "trainer_config = TrainerConfig(auto_lr_find=True, batch_size=30, max_epochs=100, gpus=None)\n",
    "optimizer_config = OptimizerConfig()\n",
    "model_config = CategoryEmbeddingModelConfig(task=\"regression\", layers=\"5-128-1\", activation=\"ReLU\", learning_rate = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_model = TabularModel(data_config=data_config,model_config=model_config,\n",
    "                             optimizer_config=optimizer_config,trainer_config=trainer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>SI</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.717960</td>\n",
       "      <td>0.932338</td>\n",
       "      <td>1.126044</td>\n",
       "      <td>0.721319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>1.014883</td>\n",
       "      <td>1.392477</td>\n",
       "      <td>1.672255</td>\n",
       "      <td>0.167051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Process</th>\n",
       "      <td>1.003868</td>\n",
       "      <td>1.315344</td>\n",
       "      <td>1.590694</td>\n",
       "      <td>0.376939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MAE      RMSE        SI   Pearson\n",
       "Random Forest     0.717960  0.932338  1.126044  0.721319\n",
       "Neural Network    1.014883  1.392477  1.672255  0.167051\n",
       "Gaussian Process  1.003868  1.315344  1.590694  0.376939"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table of model metrics\n",
    "results = pd.concat([met_rf, met_nn, met_gpr])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Network</th>\n",
       "      <th>Gaussian Process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81.860974</td>\n",
       "      <td>81.247381</td>\n",
       "      <td>83.054222</td>\n",
       "      <td>82.950446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.077624</td>\n",
       "      <td>83.756269</td>\n",
       "      <td>83.738991</td>\n",
       "      <td>84.363894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.166478</td>\n",
       "      <td>83.883265</td>\n",
       "      <td>83.901985</td>\n",
       "      <td>83.852130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.600000</td>\n",
       "      <td>83.783296</td>\n",
       "      <td>83.018700</td>\n",
       "      <td>82.378750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.136733</td>\n",
       "      <td>81.952674</td>\n",
       "      <td>83.421516</td>\n",
       "      <td>81.964370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>83.464268</td>\n",
       "      <td>82.675278</td>\n",
       "      <td>83.945541</td>\n",
       "      <td>83.637604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>83.600000</td>\n",
       "      <td>82.832604</td>\n",
       "      <td>83.102966</td>\n",
       "      <td>82.536091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>83.487000</td>\n",
       "      <td>82.858764</td>\n",
       "      <td>83.069183</td>\n",
       "      <td>82.406824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>83.900000</td>\n",
       "      <td>83.160139</td>\n",
       "      <td>82.948380</td>\n",
       "      <td>82.175652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80.700000</td>\n",
       "      <td>81.471191</td>\n",
       "      <td>82.935799</td>\n",
       "      <td>81.464761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>81.072345</td>\n",
       "      <td>81.669437</td>\n",
       "      <td>83.349785</td>\n",
       "      <td>81.574026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>83.100000</td>\n",
       "      <td>83.383299</td>\n",
       "      <td>83.029305</td>\n",
       "      <td>82.606056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>83.705126</td>\n",
       "      <td>81.958662</td>\n",
       "      <td>83.283524</td>\n",
       "      <td>83.256264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>83.918603</td>\n",
       "      <td>82.319427</td>\n",
       "      <td>82.972954</td>\n",
       "      <td>83.430500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>84.376518</td>\n",
       "      <td>83.861865</td>\n",
       "      <td>83.753403</td>\n",
       "      <td>84.436597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>81.729413</td>\n",
       "      <td>81.732038</td>\n",
       "      <td>83.207794</td>\n",
       "      <td>83.166572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>82.900000</td>\n",
       "      <td>83.267699</td>\n",
       "      <td>83.027977</td>\n",
       "      <td>82.769047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>83.318034</td>\n",
       "      <td>83.326477</td>\n",
       "      <td>83.709633</td>\n",
       "      <td>83.220475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>80.721815</td>\n",
       "      <td>81.067086</td>\n",
       "      <td>83.053123</td>\n",
       "      <td>83.033382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>83.200000</td>\n",
       "      <td>82.829965</td>\n",
       "      <td>82.838806</td>\n",
       "      <td>82.177500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>82.700000</td>\n",
       "      <td>82.786909</td>\n",
       "      <td>82.829155</td>\n",
       "      <td>81.648328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>81.797869</td>\n",
       "      <td>81.921712</td>\n",
       "      <td>83.334549</td>\n",
       "      <td>82.129543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>83.771029</td>\n",
       "      <td>82.769006</td>\n",
       "      <td>83.546814</td>\n",
       "      <td>82.732758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>80.212120</td>\n",
       "      <td>79.828487</td>\n",
       "      <td>82.960693</td>\n",
       "      <td>80.954832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>81.307675</td>\n",
       "      <td>84.224039</td>\n",
       "      <td>86.612259</td>\n",
       "      <td>87.003332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>80.628168</td>\n",
       "      <td>79.751993</td>\n",
       "      <td>82.688026</td>\n",
       "      <td>80.894813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>82.700000</td>\n",
       "      <td>83.147181</td>\n",
       "      <td>83.032036</td>\n",
       "      <td>82.284835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>82.110214</td>\n",
       "      <td>82.263538</td>\n",
       "      <td>83.448586</td>\n",
       "      <td>82.162275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>83.474423</td>\n",
       "      <td>84.115958</td>\n",
       "      <td>83.882553</td>\n",
       "      <td>84.302952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>84.300000</td>\n",
       "      <td>83.067275</td>\n",
       "      <td>82.960739</td>\n",
       "      <td>82.218790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>84.815697</td>\n",
       "      <td>84.298388</td>\n",
       "      <td>84.084274</td>\n",
       "      <td>84.228640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>82.566041</td>\n",
       "      <td>82.544459</td>\n",
       "      <td>82.955910</td>\n",
       "      <td>81.727853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>84.800000</td>\n",
       "      <td>83.474985</td>\n",
       "      <td>82.852661</td>\n",
       "      <td>82.198615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>85.637471</td>\n",
       "      <td>83.979323</td>\n",
       "      <td>83.861984</td>\n",
       "      <td>83.992545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>82.687124</td>\n",
       "      <td>80.926427</td>\n",
       "      <td>83.004173</td>\n",
       "      <td>81.904511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>81.500000</td>\n",
       "      <td>83.203114</td>\n",
       "      <td>82.966972</td>\n",
       "      <td>81.985608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>83.500000</td>\n",
       "      <td>83.506449</td>\n",
       "      <td>82.908821</td>\n",
       "      <td>82.475738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>83.300000</td>\n",
       "      <td>83.419220</td>\n",
       "      <td>82.978195</td>\n",
       "      <td>82.259677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>83.200000</td>\n",
       "      <td>83.299764</td>\n",
       "      <td>83.058769</td>\n",
       "      <td>82.247144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>83.375000</td>\n",
       "      <td>83.066847</td>\n",
       "      <td>83.035309</td>\n",
       "      <td>82.494095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>83.139045</td>\n",
       "      <td>83.415522</td>\n",
       "      <td>83.891991</td>\n",
       "      <td>83.639346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>84.353969</td>\n",
       "      <td>84.240618</td>\n",
       "      <td>83.997116</td>\n",
       "      <td>83.815841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>82.165872</td>\n",
       "      <td>81.531680</td>\n",
       "      <td>83.058678</td>\n",
       "      <td>82.301229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>83.697478</td>\n",
       "      <td>83.417993</td>\n",
       "      <td>83.684288</td>\n",
       "      <td>83.198866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>83.609844</td>\n",
       "      <td>83.813559</td>\n",
       "      <td>82.963196</td>\n",
       "      <td>82.038896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>81.604445</td>\n",
       "      <td>83.791168</td>\n",
       "      <td>83.949883</td>\n",
       "      <td>84.376967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>79.998906</td>\n",
       "      <td>79.437843</td>\n",
       "      <td>82.783928</td>\n",
       "      <td>81.068433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>84.513280</td>\n",
       "      <td>83.734827</td>\n",
       "      <td>83.011375</td>\n",
       "      <td>82.566136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>83.217715</td>\n",
       "      <td>83.757616</td>\n",
       "      <td>82.987251</td>\n",
       "      <td>82.501554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>81.400000</td>\n",
       "      <td>83.038205</td>\n",
       "      <td>83.096298</td>\n",
       "      <td>82.246421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>82.400000</td>\n",
       "      <td>83.163257</td>\n",
       "      <td>83.008293</td>\n",
       "      <td>82.156176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>83.391335</td>\n",
       "      <td>82.413503</td>\n",
       "      <td>83.120972</td>\n",
       "      <td>83.004386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>83.215721</td>\n",
       "      <td>83.214086</td>\n",
       "      <td>83.652298</td>\n",
       "      <td>82.840789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>83.883813</td>\n",
       "      <td>83.782510</td>\n",
       "      <td>83.776276</td>\n",
       "      <td>84.096247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>82.443000</td>\n",
       "      <td>83.423545</td>\n",
       "      <td>82.977295</td>\n",
       "      <td>82.468560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>83.548298</td>\n",
       "      <td>84.092111</td>\n",
       "      <td>83.824913</td>\n",
       "      <td>83.241000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>82.509617</td>\n",
       "      <td>80.879344</td>\n",
       "      <td>82.994423</td>\n",
       "      <td>81.739115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>82.611388</td>\n",
       "      <td>81.468516</td>\n",
       "      <td>83.084412</td>\n",
       "      <td>83.144431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>83.641475</td>\n",
       "      <td>83.678126</td>\n",
       "      <td>83.038086</td>\n",
       "      <td>82.756939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>79.879757</td>\n",
       "      <td>81.324650</td>\n",
       "      <td>83.023842</td>\n",
       "      <td>82.939260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>81.400000</td>\n",
       "      <td>82.008351</td>\n",
       "      <td>82.852592</td>\n",
       "      <td>81.786902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>83.747725</td>\n",
       "      <td>83.754663</td>\n",
       "      <td>83.881393</td>\n",
       "      <td>83.592404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>84.200000</td>\n",
       "      <td>83.443900</td>\n",
       "      <td>83.104073</td>\n",
       "      <td>82.623066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>83.697089</td>\n",
       "      <td>83.565393</td>\n",
       "      <td>83.575333</td>\n",
       "      <td>83.411664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>83.356190</td>\n",
       "      <td>82.222802</td>\n",
       "      <td>83.067032</td>\n",
       "      <td>82.898793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>80.771721</td>\n",
       "      <td>82.086663</td>\n",
       "      <td>83.026222</td>\n",
       "      <td>82.738726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>82.413747</td>\n",
       "      <td>81.752093</td>\n",
       "      <td>83.378372</td>\n",
       "      <td>81.367515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>83.243553</td>\n",
       "      <td>83.077858</td>\n",
       "      <td>82.602852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>82.506665</td>\n",
       "      <td>83.060586</td>\n",
       "      <td>83.114365</td>\n",
       "      <td>82.051110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>79.700000</td>\n",
       "      <td>80.829881</td>\n",
       "      <td>82.962334</td>\n",
       "      <td>81.476614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>85.531703</td>\n",
       "      <td>84.241134</td>\n",
       "      <td>84.012505</td>\n",
       "      <td>84.168436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>83.658227</td>\n",
       "      <td>83.444174</td>\n",
       "      <td>84.372726</td>\n",
       "      <td>84.067150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>84.548860</td>\n",
       "      <td>83.723387</td>\n",
       "      <td>83.037804</td>\n",
       "      <td>82.790681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>81.878416</td>\n",
       "      <td>83.477680</td>\n",
       "      <td>83.770493</td>\n",
       "      <td>83.885793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>83.400000</td>\n",
       "      <td>83.032596</td>\n",
       "      <td>82.893791</td>\n",
       "      <td>81.952215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>84.069000</td>\n",
       "      <td>83.918414</td>\n",
       "      <td>83.058731</td>\n",
       "      <td>82.903622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>83.500000</td>\n",
       "      <td>82.999235</td>\n",
       "      <td>82.864807</td>\n",
       "      <td>82.150051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>79.300000</td>\n",
       "      <td>80.309082</td>\n",
       "      <td>83.043129</td>\n",
       "      <td>81.637193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>80.987944</td>\n",
       "      <td>79.500983</td>\n",
       "      <td>82.846077</td>\n",
       "      <td>81.189610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>83.252420</td>\n",
       "      <td>83.095262</td>\n",
       "      <td>83.050171</td>\n",
       "      <td>81.994444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>83.365150</td>\n",
       "      <td>82.953087</td>\n",
       "      <td>82.499548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82.780156</td>\n",
       "      <td>82.913877</td>\n",
       "      <td>82.967682</td>\n",
       "      <td>82.020196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83.300000</td>\n",
       "      <td>83.409189</td>\n",
       "      <td>83.085800</td>\n",
       "      <td>82.372693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83.400000</td>\n",
       "      <td>83.330351</td>\n",
       "      <td>82.996620</td>\n",
       "      <td>82.380337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>82.700000</td>\n",
       "      <td>83.185976</td>\n",
       "      <td>83.047501</td>\n",
       "      <td>82.453445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>83.021000</td>\n",
       "      <td>83.426625</td>\n",
       "      <td>82.976845</td>\n",
       "      <td>82.578145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>82.295000</td>\n",
       "      <td>82.822595</td>\n",
       "      <td>83.023933</td>\n",
       "      <td>82.280105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>81.852761</td>\n",
       "      <td>83.804091</td>\n",
       "      <td>83.867386</td>\n",
       "      <td>83.959625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>80.764841</td>\n",
       "      <td>82.472094</td>\n",
       "      <td>82.944069</td>\n",
       "      <td>82.422688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>84.100000</td>\n",
       "      <td>83.097146</td>\n",
       "      <td>83.101875</td>\n",
       "      <td>82.448570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Test set  Random Forest  Neural Network  Gaussian Process\n",
       "0   81.860974      81.247381       83.054222         82.950446\n",
       "1   84.077624      83.756269       83.738991         84.363894\n",
       "2   84.166478      83.883265       83.901985         83.852130\n",
       "3   83.600000      83.783296       83.018700         82.378750\n",
       "4   83.136733      81.952674       83.421516         81.964370\n",
       "5   83.464268      82.675278       83.945541         83.637604\n",
       "6   83.600000      82.832604       83.102966         82.536091\n",
       "7   83.487000      82.858764       83.069183         82.406824\n",
       "8   83.900000      83.160139       82.948380         82.175652\n",
       "9   80.700000      81.471191       82.935799         81.464761\n",
       "10  81.072345      81.669437       83.349785         81.574026\n",
       "11  83.100000      83.383299       83.029305         82.606056\n",
       "12  83.705126      81.958662       83.283524         83.256264\n",
       "13  83.918603      82.319427       82.972954         83.430500\n",
       "14  84.376518      83.861865       83.753403         84.436597\n",
       "15  81.729413      81.732038       83.207794         83.166572\n",
       "16  82.900000      83.267699       83.027977         82.769047\n",
       "17  83.318034      83.326477       83.709633         83.220475\n",
       "18  80.721815      81.067086       83.053123         83.033382\n",
       "19  83.200000      82.829965       82.838806         82.177500\n",
       "20  82.700000      82.786909       82.829155         81.648328\n",
       "21  81.797869      81.921712       83.334549         82.129543\n",
       "22  83.771029      82.769006       83.546814         82.732758\n",
       "23  80.212120      79.828487       82.960693         80.954832\n",
       "24  81.307675      84.224039       86.612259         87.003332\n",
       "25  80.628168      79.751993       82.688026         80.894813\n",
       "26  82.700000      83.147181       83.032036         82.284835\n",
       "27  82.110214      82.263538       83.448586         82.162275\n",
       "28  83.474423      84.115958       83.882553         84.302952\n",
       "29  84.300000      83.067275       82.960739         82.218790\n",
       "30  84.815697      84.298388       84.084274         84.228640\n",
       "31  82.566041      82.544459       82.955910         81.727853\n",
       "32  84.800000      83.474985       82.852661         82.198615\n",
       "33  85.637471      83.979323       83.861984         83.992545\n",
       "34  82.687124      80.926427       83.004173         81.904511\n",
       "35  81.500000      83.203114       82.966972         81.985608\n",
       "36  83.500000      83.506449       82.908821         82.475738\n",
       "37  83.300000      83.419220       82.978195         82.259677\n",
       "38  83.200000      83.299764       83.058769         82.247144\n",
       "39  83.375000      83.066847       83.035309         82.494095\n",
       "40  83.139045      83.415522       83.891991         83.639346\n",
       "41  84.353969      84.240618       83.997116         83.815841\n",
       "42  82.165872      81.531680       83.058678         82.301229\n",
       "43  83.697478      83.417993       83.684288         83.198866\n",
       "44  83.609844      83.813559       82.963196         82.038896\n",
       "45  81.604445      83.791168       83.949883         84.376967\n",
       "46  79.998906      79.437843       82.783928         81.068433\n",
       "47  84.513280      83.734827       83.011375         82.566136\n",
       "48  83.217715      83.757616       82.987251         82.501554\n",
       "49  81.400000      83.038205       83.096298         82.246421\n",
       "50  82.400000      83.163257       83.008293         82.156176\n",
       "51  83.391335      82.413503       83.120972         83.004386\n",
       "52  83.215721      83.214086       83.652298         82.840789\n",
       "53  83.883813      83.782510       83.776276         84.096247\n",
       "54  82.443000      83.423545       82.977295         82.468560\n",
       "55  83.548298      84.092111       83.824913         83.241000\n",
       "56  82.509617      80.879344       82.994423         81.739115\n",
       "57  82.611388      81.468516       83.084412         83.144431\n",
       "58  83.641475      83.678126       83.038086         82.756939\n",
       "59  79.879757      81.324650       83.023842         82.939260\n",
       "60  81.400000      82.008351       82.852592         81.786902\n",
       "61  83.747725      83.754663       83.881393         83.592404\n",
       "62  84.200000      83.443900       83.104073         82.623066\n",
       "63  83.697089      83.565393       83.575333         83.411664\n",
       "64  83.356190      82.222802       83.067032         82.898793\n",
       "65  80.771721      82.086663       83.026222         82.738726\n",
       "66  82.413747      81.752093       83.378372         81.367515\n",
       "67  84.000000      83.243553       83.077858         82.602852\n",
       "68  82.506665      83.060586       83.114365         82.051110\n",
       "69  79.700000      80.829881       82.962334         81.476614\n",
       "70  85.531703      84.241134       84.012505         84.168436\n",
       "71  83.658227      83.444174       84.372726         84.067150\n",
       "72  84.548860      83.723387       83.037804         82.790681\n",
       "73  81.878416      83.477680       83.770493         83.885793\n",
       "74  83.400000      83.032596       82.893791         81.952215\n",
       "75  84.069000      83.918414       83.058731         82.903622\n",
       "76  83.500000      82.999235       82.864807         82.150051\n",
       "77  79.300000      80.309082       83.043129         81.637193\n",
       "78  80.987944      79.500983       82.846077         81.189610\n",
       "79  83.252420      83.095262       83.050171         81.994444\n",
       "80  84.600000      83.365150       82.953087         82.499548\n",
       "81  82.780156      82.913877       82.967682         82.020196\n",
       "82  83.300000      83.409189       83.085800         82.372693\n",
       "83  83.400000      83.330351       82.996620         82.380337\n",
       "84  82.700000      83.185976       83.047501         82.453445\n",
       "85  83.021000      83.426625       82.976845         82.578145\n",
       "86  82.295000      82.822595       83.023933         82.280105\n",
       "87  81.852761      83.804091       83.867386         83.959625\n",
       "88  80.764841      82.472094       82.944069         82.422688\n",
       "89  84.100000      83.097146       83.101875         82.448570"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table for Value comparison\n",
    "Y_values = pd.DataFrame(np.concatenate((Y_test, Y_rf, Y_nn, Y_gpr), axis=1))\n",
    "Y_values.set_axis(['Test set','Random Forest', 'Neural Network', 'Gaussian Process'], axis=1, inplace=True)\n",
    "Y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=3, ncols=1, figsize=(16,20))\n",
    "plt.suptitle('Predicted data', fontsize='xx-large', y=0.9)\n",
    "ax[0].plot(Y_rf, '--b',label = 'Random Forest')\n",
    "ax[0].plot(Y_test, '-r',label = 'Test data')\n",
    "ax[0].tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "ax[0].set_ylabel('T3028 Yield [%]')\n",
    "ax[0].legend()\n",
    "ax[1].plot(Y_nn, '--b',label = 'Neural Network')\n",
    "ax[1].plot(Y_test, '-r',label = 'Test data')\n",
    "ax[1].tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "ax[1].set_ylabel('T3028 Yield [%]')\n",
    "ax[1].legend()\n",
    "ax[2].plot(Y_gpr, '--b',label = 'Gaussian Process')\n",
    "ax[2].plot(Y_test, '-r',label = 'Test data')\n",
    "ax[2].tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "ax[2].set_ylabel('T3028 Yield [%]')\n",
    "ax[2].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Graph2](Graph2.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
