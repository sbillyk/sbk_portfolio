{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TechLabs WS21, Data Extraction\n",
    "### Stefanus Kohar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work notes :\n",
    "- openpyxl module is not used, a problem occured while the module is used (data is missing after extraction)\n",
    "- _df.groupby_ documentation : https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html\n",
    "- future addition : collapsible cells (jupyter-contrib-nbextensions)\n",
    "- further development cell is intended to develop an automated sheet name extraction, thus allowing multiple data timeframe  extraction automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Future development cell, automatically pulling sheet names\n",
    "sheet = pd.ExcelFile(\"sample.xlsx\")\n",
    "sheet_count = len(sheet.sheet_names)\n",
    "\n",
    "#for i in sheet.sheet_names :\n",
    "#    print(i[-2:])\n",
    "\n",
    "list(sheet.sheet_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "___Please run function cells before continuing further___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_extract(file, sheet)_ function was created to simplify the file extraction, file and sheet is related to the file directory and sheet number of the data\n",
    "\n",
    "_pre_mean(col)_ function was created to pull a preliminary representation on material A\n",
    "\n",
    "AB(a) and BD(a) functions were created for value processing based on related properties. Input value a is the extracted file related to the observed timeframe. Process explanation is given below the function code cell.\n",
    "\n",
    "AD(a,b) function is created to bring forward the properties from material A to material D. Process explanation is given below the function code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file, sheet) :\n",
    "#   (1) Excel file extraction\n",
    "    global MSTR_2\n",
    "    A_1 = pd.read_excel(file, sheet_name=sheet)\n",
    "    MSTR_2 = MSTR_2.rename(columns={MSTR_2.columns[0] : A_1.columns[0]})\n",
    "    A_1.replace(to_replace=r' ', value='' , regex=True, inplace=True)\n",
    "    A_1.replace(to_replace=r',', value='.' , regex=True, inplace=True)\n",
    "    A_1.replace(to_replace='[\\n(]TC[)]', value='' , regex=True, inplace=True)\n",
    "    A_1.replace(to_replace='\\n', value='' , regex=True, inplace=True)\n",
    "    A = A_1.merge(MSTR_2, on=A_1.columns[0], how='left')\n",
    "    return A\n",
    "\n",
    "def pre_mean(col) :\n",
    "    global MSTR_TA, MSTR_TB, MSTR_TC\n",
    "    TA = MSTR_TA.iloc[:,[0,col]]\n",
    "    TA = TA.groupby(TA.columns[0]).mean()\n",
    "    TA.reset_index(drop=True, inplace=True)\n",
    "    TB = MSTR_TB.iloc[:,[0,col]]\n",
    "    TB = TB.groupby(TB.columns[0]).mean()\n",
    "    TB.reset_index(drop=True, inplace=True)\n",
    "    TC = MSTR_TC.iloc[:,[0,col]]\n",
    "    TC = TC.groupby(TC.columns[0]).mean()\n",
    "    TC.reset_index(drop=True, inplace=True)\n",
    "    A = pd.concat([TA, TB, TC], axis = 1)\n",
    "    return A\n",
    "\n",
    "def AB(a) :\n",
    "#   (2) Extracting related columns\n",
    "    R = a.iloc[:,[0,10,20,30,40]].copy()\n",
    "    R[R.columns[0]].ffill(inplace=True)\n",
    "    AtoB = pd.DataFrame()\n",
    "    \n",
    "#   (3) Identifier of unique batch numbers and creating data subset of the related batch number\n",
    "    for i in R[R.columns[0]].unique() :\n",
    "        A = R[R[R.columns[0]] == i]\n",
    "        A.reset_index(drop=True, inplace = True)\n",
    "        B_batch = []\n",
    "        B_ind = []\n",
    "        \n",
    "#       Obtaining index of rows containing the value of lower material\n",
    "        for j in range(A.shape[0]):\n",
    "            \n",
    "            if pd.isnull(A.loc[j,A.columns[1]]) == False :\n",
    "                B_batch.append(A.loc[j,A.columns[1]])\n",
    "                B_ind.append(j)\n",
    "        B_ind.append(A.shape[0])\n",
    "        ctr = 0\n",
    "        \n",
    "        for j in B_ind :\n",
    "            \n",
    "            if(B_ind[ctr]!=A.shape[0]) :\n",
    "                ctr += 1\n",
    "                top_ctr = B_ind[ctr]\n",
    "                A_metA = 0\n",
    "                A_metB = 0\n",
    "                A_metC = 0\n",
    "                A_metD = 0\n",
    "                A_metD = 0\n",
    "                \n",
    "#               (4) Loop for weighted sum calculation\n",
    "                for k in range(j, top_ctr) :\n",
    "                    A_metA += (A[A.columns[3]][k])\n",
    "                    A_metB += (A[A.columns[3]][k])*(A[A.columns[4]][k])\n",
    "                    A_metC += (A[A.columns[3]][k])*(A[A.columns[5]][k])\n",
    "                    A_metD += (A[A.columns[3]][k])*(A[A.columns[6]][k])\n",
    "                    A_metD += (A[A.columns[3]][k])*(A[A.columns[7]][k])\n",
    "                A_metB = A_metB / A_metA\n",
    "                A_metC = A_metC / A_metA\n",
    "                A_metD = A_metD / A_metA\n",
    "                A_metD = A_metD / A_metA\n",
    "\n",
    "                A.loc[[j], 'Column A'] = A_metA.copy()\n",
    "                A.loc[[j], 'Column B'] = A_metB.copy()\n",
    "                A.loc[[j], 'Column C'] = A_metC.copy()\n",
    "                A.loc[[j], 'Column D'] = A_metD.copy()\n",
    "                A.loc[[j], 'Column E'] = A_metD.copy()\n",
    "        \n",
    "#       (5) Cleanup, sequential addition and renaming columns\n",
    "        A.drop(columns=[A.columns[0],A.columns[2],A.columns[3],A.columns[4],A.columns[5],A.columns[6]\n",
    "                        ,A.columns[7]], inplace=True)\n",
    "        A = A[A[A.columns[4]].notna()]\n",
    "        AtoB = AtoB.append(A, ignore_index=True)\n",
    "    AtoB = AtoB.groupby(AtoB.columns[0], as_index=False).mean()\n",
    "    AtoB_index = ['Column A', 'Column B', 'Column C', 'Column D', \n",
    "                  'Column E', 'Column F', 'Column G', 'Column H']\n",
    "    AtoB.set_axis(AtoB_index, axis=1, inplace=True)\n",
    "    return AtoB\n",
    "\n",
    "def BD(a) :\n",
    "#   (2) Extracting related columns\n",
    "    R = a.iloc[:,[0,10,20,30,40]].copy()\n",
    "    R = R[R[R.columns[1]].notna()]\n",
    "    R[R.columns[0]].ffill(inplace=True)\n",
    "    BtoD = pd.DataFrame()\n",
    "\n",
    "#   (3) Identifier of unique batch numbers and creating data subset of the related batch number\n",
    "    for i in R[R.columns[0]].unique() :\n",
    "        B = R[R[R.columns[0]] == i]\n",
    "        B.reset_index(drop=True, inplace = True)\n",
    "        D_batch = []\n",
    "        D_ind = []\n",
    "\n",
    "#       Obtaining index of rows containing the value of lower material\n",
    "        for j in range(B.shape[0]):\n",
    "            if pd.isnull(B.loc[j,B.columns[1]]) == False :\n",
    "                D_batch.append(B.loc[j,B.columns[1]])\n",
    "                D_ind.append(j)\n",
    "        D_ind.append(B.shape[0])\n",
    "\n",
    "        B_metA = 0\n",
    "        B_metB = 0\n",
    "        \n",
    "#       (4) Loop for weighted sum calculation\n",
    "        for j in D_ind :\n",
    "            if(j!=B.shape[0]) :\n",
    "                B_metA += B[B.columns[2]][j]\n",
    "                B_metB += (B[B.columns[2]][j])*(B[B.columns[3]][j])\n",
    "        B_metB = B_metB / B_metA\n",
    "        B.loc[[0],['Column A']] = B_metA\n",
    "        B.loc[[0],['Column B']] = B_metB\n",
    "\n",
    "#       (5) Cleanup, sequential addition and renaming columns\n",
    "        B.drop(columns=[B.columns[1],B.columns[2],B.columns[3]], inplace=True)\n",
    "        BtoD = BtoD.append(B, ignore_index=True)\n",
    "    BtoD = BtoD.groupby(BtoD.columns[0], as_index=False).mean()\n",
    "    BtoD_index = ['Column A', 'Column B', 'Column C', 'Column D', \n",
    "                  'Column E', 'Column F', 'Column G', 'Column H']\n",
    "    BtoD.set_axis(BtoD_index, axis=1, inplace=True)\n",
    "    BtoD.dropna(inplace=True)\n",
    "    BtoD.reset_index(drop=True, inplace = True)\n",
    "    return BtoD\n",
    "\n",
    "def AD(a,b) :\n",
    "#   (2) Extracting related columns\n",
    "    R = a.iloc[:,[0,10,20,30,40]].copy()\n",
    "    R = R[R[R.columns[1]].notna()]\n",
    "    \n",
    "#   (6) obtaining feature values from AB function output\n",
    "    R2 = b.iloc[:,[0,10,20,30,40]]\n",
    "    R[R.columns[0]].ffill(inplace=True)\n",
    "    R2.rename(columns={R2.columns[0] : R.columns[1]}, inplace=True)\n",
    "    R = R.merge(R2, on=R.columns[1], how='left')\n",
    "    AtoD = pd.DataFrame()\n",
    "\n",
    "#   (3) Identifier of unique batch numbers and creating data subset of the related batch number\n",
    "    for i in R[R.columns[0]].unique() :\n",
    "        B = R[R[R.columns[0]] == i]\n",
    "        B.reset_index(drop=True, inplace = True)\n",
    "        D_batch = []\n",
    "        D_ind = []\n",
    "\n",
    "#       Obtaining index of rows containing the value of lower material\n",
    "        for j in range(B.shape[0]):\n",
    "            if pd.isnull(B.loc[j,B.columns[1]]) == False :\n",
    "                D_batch.append(B.loc[j,B.columns[1]])\n",
    "                D_ind.append(j)\n",
    "        D_ind.append(B.shape[0])\n",
    "\n",
    "        B_metA = 0\n",
    "        B_metC = 0\n",
    "        B_metD = 0\n",
    "        B_metE = 0\n",
    "        B_metF = 0\n",
    "        \n",
    "#       (4) Loop for weighted sum calculation\n",
    "        for j in D_ind :\n",
    "            if(j!=B.shape[0]) :\n",
    "                B_metA += B[B.columns[2]][j]\n",
    "                B_metC += (B[B.columns[2]][j])*(B[B.columns[8]][j])\n",
    "                B_metD += (B[B.columns[2]][j])*(B[B.columns[9]][j])\n",
    "                B_metE += (B[B.columns[2]][j])*(B[B.columns[10]][j])\n",
    "                B_metF += (B[B.columns[2]][j])*(B[B.columns[11]][j])\n",
    "        B_metC = B_metC / B_metA\n",
    "        B_metD = B_metD / B_metA\n",
    "        B_metE = B_metE / B_metA\n",
    "        B_metF = B_metF / B_metA\n",
    "        B.loc[[0],['Column A']] = B_metA\n",
    "        B.loc[[0],['Column C']] = B_metC\n",
    "        B.loc[[0],['Column D']] = B_metD\n",
    "        B.loc[[0],['Column E']] = B_metE\n",
    "        B.loc[[0],['Column F']] = B_metF\n",
    "\n",
    "#       (5) Cleanup, sequential addition and renaming columns\n",
    "        B.drop(columns=[B.columns[1],B.columns[2],B.columns[8],B.columns[9],B.columns[10],B.columns[11]], inplace=True)\n",
    "        AtoD = AtoD.append(B, ignore_index=True)\n",
    "    AtoD = AtoD.groupby(AtoD.columns[0], as_index=False).mean()\n",
    "    AtoD_index = ['Column A', 'Column B', 'Column C', 'Column D', \n",
    "                  'Column E', 'Column F', 'Column G', 'Column H', \n",
    "                  'Column I', 'Column J', 'Column K']\n",
    "    AtoD.set_axis(AtoD_index, axis=1, inplace=True)\n",
    "    AtoD.dropna(inplace=True)\n",
    "    AtoD.reset_index(drop=True, inplace = True)\n",
    "    return AtoD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Material Value Processing__\n",
    "\n",
    "In the following cells, the data preparation for the following processes is explained.\n",
    "\n",
    "The way calculations are done through function AB(a) and BD(a) : \n",
    "\n",
    "Main alteration to the code algorithm is within the input data and row-column adjustments. Parts of the code above is marked with (x) in regards to the explanation in this paragraph\n",
    "\n",
    "(1) The source excel file is imported into a DataFrame and named as MSTR_XX, where XX signifies the sheet of the data (e.g. TA for Sheet A) The raw unaltered DataFrame has gaps which actually contain similar values to the last value above the NA field. This is due to the formatting in the source file. \n",
    "\n",
    "The basic concept of the calculation is weighted sum, where the amount of added material carries a proportional feature values to final mixture.\n",
    "\n",
    "(2) For the related process step, only the related columns of the source dataframe are extracted into the processing function.\n",
    "\n",
    "(3) We use the batch column of the higher material as a identifier for the feature values of the lower material will be stored into. .unique() method creates a list of available item in that column, which is used to create subsets of data containing only the related item of the material.<br>\n",
    "\n",
    "(4) We then insert another loop which is used to iterate inside the subsets of data, to do the weighted sum calculation for the feature values.<br>\n",
    "\n",
    "(5) The final calculated values is then inserted into a new column. These subsets of data are the sequentially added into a DataFrame, which then will be the output of the function.<br>\n",
    "\n",
    "\n",
    "For function AD(a,b) : \n",
    "\n",
    "(6) Instead of obtaining the feature values from the source DataFrame, the output from function AB is used and processed using the weighted sum method.<br>\n",
    "\n",
    "To round things up, NaN values are omitted <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting excel files\n",
    "MSTR_2 = pd.read_excel(\"sample_2.xlsx\")\n",
    "MSTR_2[MSTR_2.columns[2]].replace(to_replace=r'\\t', value='' , regex=True, inplace=True)\n",
    "MSTR_2[MSTR_2.columns[2]].replace(to_replace=r',', value='.' , regex=True, inplace=True)\n",
    "MSTR_2[MSTR_2.columns[2]] = MSTR_2[MSTR_2.columns[2]].astype('float64')\n",
    "\n",
    "file = \"sample.xlsx\"\n",
    "MSTR_TC = extract(file, \"Sheet C\")\n",
    "MSTR_TB = extract(file, \"Sheet B\")\n",
    "MSTR_TA = extract(file, \"Sheet A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary Metric preview, data processing\n",
    "metA = pre_mean(4)\n",
    "metB = pre_mean(27)\n",
    "metC = pre_mean(28)\n",
    "\n",
    "Sheet = ['Sheet A','Sheet B','Sheet C']\n",
    "metA = metA.set_axis(Sheet, axis = 1)\n",
    "metB = metB.set_axis(Sheet, axis = 1)\n",
    "metC = metC.set_axis(Sheet, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This plot displays the observed value variance and verify correct extraction of data\n",
    "sns.set()\n",
    "f, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,6))\n",
    "sns.boxplot(ax=ax[0], data=Yield, orient=\"v\", color=\"#08a35c\")\n",
    "ax[0].title.set_text('Metric A')\n",
    "sns.boxplot(ax=ax[1], data=IMP1, orient=\"v\", color=\"#08a35c\")\n",
    "ax[1].title.set_text('Metric B')\n",
    "sns.boxplot(ax=ax[2], data=IMP2, orient=\"v\", color=\"#08a35c\")\n",
    "ax[2].title.set_text('Metric C')\n",
    "plt.suptitle('Value variance on observed data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Graph1](Graph1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matA to matB value processing\n",
    "AB_TA = AB(MSTR_TA)\n",
    "AB_TB = AB(MSTR_TB)\n",
    "AB_TC = AB(MSTR_TC)\n",
    "\n",
    "# matB to matD value processing\n",
    "BD_TA = BD(MSTR_TA)\n",
    "BD_TB = BD(MSTR_TB)\n",
    "BD_TC = BD(MSTR_TC)\n",
    "\n",
    "# matA to matD value processing\n",
    "AD_TA = AD(MSTR_TA, AB_TA)\n",
    "AD_TB = AD(MSTR_TB, AB_TB)\n",
    "AD_TC = AD(MSTR_TC, AB_TC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To write combined file into excel format, for manual verification\n",
    "writer = pd.ExcelWriter('A-to-B.xlsx')\n",
    "AB_TC.to_excel(writer, sheet_name='Sheet C', index=False)\n",
    "AB_TB.to_excel(writer, sheet_name='Sheet B', index=False)\n",
    "AB_TA.to_excel(writer, sheet_name='Sheet A', index=False)\n",
    "writer.save()\n",
    "\n",
    "AB = pd.concat([AB_TA, AB_TB, AB_TC], ignore_index = True)\n",
    "writer = pd.ExcelWriter('A-to-B_combined.xlsx')\n",
    "AB.to_excel(writer, index=False)\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter('B-to-D.xlsx')\n",
    "BD_TC.to_excel(writer, sheet_name='Sheet C', index=False)\n",
    "BD_TB.to_excel(writer, sheet_name='Sheet B', index=False)\n",
    "BD_TA.to_excel(writer, sheet_name='Sheet A', index=False)\n",
    "writer.save()\n",
    "\n",
    "BD = pd.concat([BD_TA, BD_TB, BD_TC], ignore_index = True)\n",
    "writer = pd.ExcelWriter('B-to-D_combined.xlsx')\n",
    "BD.to_excel(writer, index=False)\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter('A-to-D.xlsx')\n",
    "AD_TC.to_excel(writer, sheet_name='Sheet C', index=False)\n",
    "AD_TB.to_excel(writer, sheet_name='Sheet B', index=False)\n",
    "AD_TA.to_excel(writer, sheet_name='Sheet A', index=False)\n",
    "writer.save()\n",
    "\n",
    "AD = pd.concat([AD_TA, AD_TB, AD_TC], ignore_index = True)\n",
    "writer = pd.ExcelWriter('A-to-D_combined.xlsx')\n",
    "AD.to_excel(writer, index=False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
